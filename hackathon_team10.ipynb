{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hackathon_team10",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simba328/2019_cau_oss_hackathon/blob/master/hackathon_team10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AosAX9DXOlc",
        "colab_type": "text"
      },
      "source": [
        "# **0. 해커톤 진행 주의사항**\n",
        "\n",
        "**1)  개발 관련 주의사항**\n",
        "*   [1. 초기 환경 설정]은 절대 수정하지 말 것\n",
        " *  단, 사용할 데이터셋에 따라 is_mnist만 수정\n",
        "*   모든 구현은 [2. 데이터 전처리]와 [3. 모델 생성]에서만 진행\n",
        " *  데이터 전처리 후 트레이닝, 데이터 셋은 x_train_after, x_test_after 변수명을 유지해주세요.\n",
        " *  데이터셋이 달라져도 같은 모델 구조를 유지하여야함.\n",
        "*   [4. 모델 저장]과 [5. 모델 로드 및 평가]에서 team_name 변수 변경 (예.`team_name = 'team01'`)\n",
        " *  트레이닝 중간에 checkpoint를 활용하여 모델을 저장한 경우에도 파일 이름 양식 통일 필수\n",
        " *  team_name을 제외한 다른 부분은 수정하지 말 것\n",
        "*   Colab 사용중 실수로 데이터 손실이 발생할 수도 있으니 중간 결과값을 github에 업로드 \n",
        " *    \"런타임->모든 런타임 재설정\"은 절대 누르지 말 것 (저장한 모델 데이터가 모두 삭제됨)\n",
        "*   효율적인 구현 및 테스팅을 위해 GPU 가속 기능 활성화\n",
        " *    \"런타임 -> 런타임 유형변경 -> 하드웨어 가속기 -> GPU 설정\"\n",
        "*   주석을 최대한 자세히 작성\n",
        "*   Keras API 관련하여 [Keras Documentation](https://keras.io/) 참조\n",
        "\n",
        "**2) 제출 관련 주의사항**\n",
        "*  제출물\n",
        " *  소스코드 (hackathon_teamXX.ipynb)\n",
        " *  모델 구조 파일 (model_structure_teamXX.json)\n",
        " *  모델 weight 파일 (model_weight_teamXX.h5)\n",
        " *  컴파일된 모델 파일 (model_entire_teamXX.h5)\n",
        "* 제출 기한: **오후 6시**\n",
        "* 제출 방법: [GitHub README](https://github.com/cauosshackathonta/2019_cau_oss_hackathon/) 참조\n",
        "\n",
        " \n",
        "**3) 평가 관련 주의사항**\n",
        "*  모델 성능 = 테스트 데이터 셋 분류 정확도\n",
        " *  model.evaluate(x_test, y_test)\n",
        "*  제출된 모델들의 테스트 데이터 셋 분류 정확도를 기준으로 수상작 결정\n",
        "*  수상 후보들에 대해서는 소스코드를 기반으로 모델 재검증 \n",
        " \n",
        "**4) 수상 실격 사유**\n",
        "*  유사한 소스코드 or 알고리즘이 적발될 경우\n",
        "*  소스코드와 제출된 모델이 상이한 경우\n",
        "*  두 개의 데이터셋에 대해 다른 모델 구조를 사용한 경우\n",
        "*  개발 관련 주의사항을 지키지 않은 경우\n",
        " *  예: [초기 환경 설정]을 수정한 경우\n",
        "*  데이터 셋을 변조한 경우\n",
        " *  예. 테스트 데이터 셋을 트레이닝 데이터 셋에 포함하여 모델 생성 \n",
        "*  주석이 소스코드와 맞지 않거나 미비할 경우\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67lwEXhUqys1",
        "colab_type": "text"
      },
      "source": [
        "# **1. 초기 환경 설정**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms5PBBJ1qSC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals, unicode_literals\n",
        "\n",
        "# tensorflow와 tf.keras 및 관련 라이브러리 임포트\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "is_mnist = False\n",
        "\n",
        "# 데이터셋 로드\n",
        "# x_train, y_train: 트레이닝 데이터 및 레이블\n",
        "# x_test, y_test: 테스트 데이터 및 레이블\n",
        "if is_mnist:\n",
        "  data_type = 'mnist'\n",
        "  (x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data() # fashion MNIST 데이터셋인 경우,\n",
        "else:\n",
        "  data_type = 'cifar10'\n",
        "  (x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data() # cifar10 데이터셋인 경우,\n",
        "\n",
        "\n",
        "# 분류를 위해 클래스 벡터를 바이너리 매트릭스로 변환\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "\n",
        "# 총 클래스 개수\n",
        "num_classes = y_test.shape[1]\n",
        "\n",
        "# 인풋 데이터 타입\n",
        "input_shape = x_test.shape[1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9c2KLDBIhNQ",
        "colab_type": "text"
      },
      "source": [
        "# **2. 데이터 전처리**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJNgjaHvIhSS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# 데이터 전처리 (예: normalization)\n",
        "x_train_after = x_train / 255.0\n",
        "x_test_after = x_test / 255.0\n",
        "\n",
        "if is_mnist:\n",
        "  x_train_after = x_train_after.reshape(x_train.shape[0], 28, 28, 1)\n",
        "  x_test_after = x_test_after.reshape(x_test.shape[0], 28, 28, 1)\n",
        "  input_shape = x_test_after.shape[1:]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-YjppJpXBO9",
        "colab_type": "text"
      },
      "source": [
        "# **3. 모델 생성**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZP4eRmRqgRp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0de3b5ac-1196-40cf-8779-f11c8ac716fe"
      },
      "source": [
        "import os\n",
        "\n",
        "# 순차 모델 생성 (가장 기본구조)\n",
        "model = keras.Sequential()\n",
        "\n",
        "model.add(keras.layers.Conv2D(32, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu', input_shape=input_shape, kernel_initializer='he_normal'))\n",
        "print(model.output_shape)\n",
        "model.add(keras.layers.Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu', input_shape=input_shape, kernel_initializer='he_normal'))\n",
        "print(model.output_shape)\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "print(model.output_shape)\n",
        "\n",
        "model.add(keras.layers.Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu', input_shape=input_shape, kernel_initializer='he_normal'))\n",
        "print(model.output_shape)\n",
        "model.add(keras.layers.Conv2D(256, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu', input_shape=input_shape, kernel_initializer='he_normal'))\n",
        "print(model.output_shape)\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "print(model.output_shape)\n",
        "\n",
        "\n",
        "model.add(keras.layers.Conv2D(512, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu', input_shape=input_shape, kernel_initializer='he_normal'))\n",
        "print(model.output_shape)\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "print(model.output_shape)\n",
        "\n",
        "\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(1024, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(keras.layers.Dense(num_classes, kernel_regularizer=keras.regularizers.l2(0.001), activation='softmax'))\n",
        "\n",
        "# 모델 컴파일\n",
        "# optimizer: 모델을 업데이트 하는 방식\n",
        "# loss: 모델의 정확도를 판단하는 방식\n",
        "# metrics: 트레이닝 및 테스팅 성능 모니터링을 위한 평가지표\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# checkpoint\n",
        "checkpoint_path = '/content/model_weight_' + data_type + '_best.h5'\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "                                               monitor='val_acc',\n",
        "                                               save_weight_only=True,\n",
        "                                               save_best_only=True,\n",
        "                                               verbose=1)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience = 20)\n",
        "\n",
        "# 모델 트레이닝\n",
        "# batch_size: 전체 데이터셋 중 몇개씩 학습시킬 것인지\n",
        "# epoch: 학습에 전체 데이터셋이 총 몇번 이용될 것인지\n",
        "# shuffle: 학습전에 트레이닝 데이터셋을 랜덤하게 섞을 것인지\n",
        "# validation_data: 중간 성능 검증에 사용할 data set\n",
        "model.fit(x_train_after, y_train, batch_size = 256, epochs = 50, shuffle=True, validation_data=[x_test_after, y_test], callbacks=[cp_callback, early_stopping])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 32, 32, 32)\n",
            "(None, 32, 32, 64)\n",
            "(None, 16, 16, 64)\n",
            "(None, 16, 16, 128)\n",
            "(None, 16, 16, 256)\n",
            "(None, 8, 8, 256)\n",
            "(None, 8, 8, 512)\n",
            "(None, 4, 4, 512)\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "49920/50000 [============================>.] - ETA: 0s - loss: 1.6574 - acc: 0.4121\n",
            "Epoch 00001: val_acc improved from -inf to 0.56030, saving model to /content/model_weight_cifar10_best.h5\n",
            "50000/50000 [==============================] - 17s 340us/sample - loss: 1.6570 - acc: 0.4121 - val_loss: 1.2484 - val_acc: 0.5603\n",
            "Epoch 2/50\n",
            "49920/50000 [============================>.] - ETA: 0s - loss: 1.1407 - acc: 0.5963\n",
            "Epoch 00002: val_acc improved from 0.56030 to 0.64880, saving model to /content/model_weight_cifar10_best.h5\n",
            "50000/50000 [==============================] - 14s 276us/sample - loss: 1.1405 - acc: 0.5964 - val_loss: 1.0080 - val_acc: 0.6488\n",
            "Epoch 3/50\n",
            "49920/50000 [============================>.] - ETA: 0s - loss: 0.9304 - acc: 0.6777\n",
            "Epoch 00003: val_acc improved from 0.64880 to 0.68840, saving model to /content/model_weight_cifar10_best.h5\n",
            "50000/50000 [==============================] - 14s 273us/sample - loss: 0.9303 - acc: 0.6777 - val_loss: 0.9147 - val_acc: 0.6884\n",
            "Epoch 4/50\n",
            "49920/50000 [============================>.] - ETA: 0s - loss: 0.7889 - acc: 0.7270\n",
            "Epoch 00004: val_acc improved from 0.68840 to 0.73890, saving model to /content/model_weight_cifar10_best.h5\n",
            "50000/50000 [==============================] - 14s 272us/sample - loss: 0.7886 - acc: 0.7271 - val_loss: 0.7753 - val_acc: 0.7389\n",
            "Epoch 5/50\n",
            "49920/50000 [============================>.] - ETA: 0s - loss: 0.6768 - acc: 0.7678\n",
            "Epoch 00005: val_acc improved from 0.73890 to 0.75930, saving model to /content/model_weight_cifar10_best.h5\n",
            "50000/50000 [==============================] - 14s 272us/sample - loss: 0.6769 - acc: 0.7678 - val_loss: 0.7010 - val_acc: 0.7593\n",
            "Epoch 6/50\n",
            "49920/50000 [============================>.] - ETA: 0s - loss: 0.5937 - acc: 0.7968\n",
            "Epoch 00006: val_acc improved from 0.75930 to 0.77630, saving model to /content/model_weight_cifar10_best.h5\n",
            "50000/50000 [==============================] - 14s 273us/sample - loss: 0.5937 - acc: 0.7968 - val_loss: 0.6626 - val_acc: 0.7763\n",
            "Epoch 7/50\n",
            "49920/50000 [============================>.] - ETA: 0s - loss: 0.5171 - acc: 0.8252\n",
            "Epoch 00007: val_acc improved from 0.77630 to 0.78750, saving model to /content/model_weight_cifar10_best.h5\n",
            "50000/50000 [==============================] - 14s 274us/sample - loss: 0.5172 - acc: 0.8250 - val_loss: 0.6426 - val_acc: 0.7875\n",
            "Epoch 8/50\n",
            "49920/50000 [============================>.] - ETA: 0s - loss: 0.4554 - acc: 0.8449\n",
            "Epoch 00008: val_acc improved from 0.78750 to 0.79140, saving model to /content/model_weight_cifar10_best.h5\n",
            "50000/50000 [==============================] - 14s 274us/sample - loss: 0.4552 - acc: 0.8450 - val_loss: 0.6292 - val_acc: 0.7914\n",
            "Epoch 9/50\n",
            "49920/50000 [============================>.] - ETA: 0s - loss: 0.4002 - acc: 0.8648\n",
            "Epoch 00009: val_acc improved from 0.79140 to 0.80470, saving model to /content/model_weight_cifar10_best.h5\n",
            "50000/50000 [==============================] - 14s 274us/sample - loss: 0.4003 - acc: 0.8647 - val_loss: 0.6067 - val_acc: 0.8047\n",
            "Epoch 10/50\n",
            "49920/50000 [============================>.] - ETA: 0s - loss: 0.3510 - acc: 0.8820\n",
            "Epoch 00010: val_acc improved from 0.80470 to 0.81500, saving model to /content/model_weight_cifar10_best.h5\n",
            "50000/50000 [==============================] - 14s 273us/sample - loss: 0.3512 - acc: 0.8820 - val_loss: 0.5677 - val_acc: 0.8150\n",
            "Epoch 11/50\n",
            "49920/50000 [============================>.] - ETA: 0s - loss: 0.3047 - acc: 0.8981\n",
            "Epoch 00011: val_acc did not improve from 0.81500\n",
            "50000/50000 [==============================] - 13s 268us/sample - loss: 0.3048 - acc: 0.8981 - val_loss: 0.6035 - val_acc: 0.8127\n",
            "Epoch 12/50\n",
            "49920/50000 [============================>.] - ETA: 0s - loss: 0.2810 - acc: 0.9058\n",
            "Epoch 00012: val_acc did not improve from 0.81500\n",
            "50000/50000 [==============================] - 13s 269us/sample - loss: 0.2809 - acc: 0.9059 - val_loss: 0.6214 - val_acc: 0.8124\n",
            "Epoch 13/50\n",
            "49920/50000 [============================>.] - ETA: 0s - loss: 0.2397 - acc: 0.9203\n",
            "Epoch 00013: val_acc did not improve from 0.81500\n",
            "50000/50000 [==============================] - 13s 269us/sample - loss: 0.2397 - acc: 0.9203 - val_loss: 0.6637 - val_acc: 0.8104\n",
            "Epoch 14/50\n",
            "49920/50000 [============================>.] - ETA: 0s - loss: 0.2289 - acc: 0.9243\n",
            "Epoch 00014: val_acc improved from 0.81500 to 0.82100, saving model to /content/model_weight_cifar10_best.h5\n",
            "50000/50000 [==============================] - 14s 273us/sample - loss: 0.2292 - acc: 0.9242 - val_loss: 0.6146 - val_acc: 0.8210\n",
            "Epoch 15/50\n",
            "49920/50000 [============================>.] - ETA: 0s - loss: 0.2064 - acc: 0.9329\n",
            "Epoch 00015: val_acc improved from 0.82100 to 0.82120, saving model to /content/model_weight_cifar10_best.h5\n",
            "50000/50000 [==============================] - 14s 274us/sample - loss: 0.2063 - acc: 0.9329 - val_loss: 0.6289 - val_acc: 0.8212\n",
            "Epoch 16/50\n",
            "49920/50000 [============================>.] - ETA: 0s - loss: 0.1875 - acc: 0.9393\n",
            "Epoch 00016: val_acc did not improve from 0.82120\n",
            "50000/50000 [==============================] - 13s 270us/sample - loss: 0.1876 - acc: 0.9393 - val_loss: 0.6283 - val_acc: 0.8197\n",
            "Epoch 17/50\n",
            "49920/50000 [============================>.] - ETA: 0s - loss: 0.1721 - acc: 0.9451\n",
            "Epoch 00017: val_acc did not improve from 0.82120\n",
            "50000/50000 [==============================] - 13s 269us/sample - loss: 0.1721 - acc: 0.9451 - val_loss: 0.6576 - val_acc: 0.8210\n",
            "Epoch 18/50\n",
            "49920/50000 [============================>.] - ETA: 0s - loss: 0.1610 - acc: 0.9489\n",
            "Epoch 00018: val_acc improved from 0.82120 to 0.82270, saving model to /content/model_weight_cifar10_best.h5\n",
            "50000/50000 [==============================] - 14s 273us/sample - loss: 0.1608 - acc: 0.9489 - val_loss: 0.6940 - val_acc: 0.8227\n",
            "Epoch 19/50\n",
            "49920/50000 [============================>.] - ETA: 0s - loss: 0.1520 - acc: 0.9521\n",
            "Epoch 00019: val_acc did not improve from 0.82270\n",
            "50000/50000 [==============================] - 13s 267us/sample - loss: 0.1520 - acc: 0.9522 - val_loss: 0.7096 - val_acc: 0.8209\n",
            "Epoch 20/50\n",
            "49920/50000 [============================>.] - ETA: 0s - loss: 0.1406 - acc: 0.9566\n",
            "Epoch 00020: val_acc improved from 0.82270 to 0.82760, saving model to /content/model_weight_cifar10_best.h5\n",
            "50000/50000 [==============================] - 14s 271us/sample - loss: 0.1407 - acc: 0.9565 - val_loss: 0.6396 - val_acc: 0.8276\n",
            "Epoch 21/50\n",
            "49920/50000 [============================>.] - ETA: 0s - loss: 0.1312 - acc: 0.9593\n",
            "Epoch 00021: val_acc did not improve from 0.82760\n",
            "50000/50000 [==============================] - 13s 269us/sample - loss: 0.1311 - acc: 0.9593 - val_loss: 0.6744 - val_acc: 0.8241\n",
            "Epoch 22/50\n",
            "49920/50000 [============================>.] - ETA: 0s - loss: 0.1265 - acc: 0.9605\n",
            "Epoch 00022: val_acc did not improve from 0.82760\n",
            "50000/50000 [==============================] - 14s 270us/sample - loss: 0.1266 - acc: 0.9604 - val_loss: 0.6609 - val_acc: 0.8276\n",
            "Epoch 23/50\n",
            "49920/50000 [============================>.] - ETA: 0s - loss: 0.1288 - acc: 0.9603\n",
            "Epoch 00023: val_acc did not improve from 0.82760\n",
            "50000/50000 [==============================] - 13s 268us/sample - loss: 0.1288 - acc: 0.9603 - val_loss: 0.7068 - val_acc: 0.8186\n",
            "Epoch 24/50\n",
            "49920/50000 [============================>.] - ETA: 0s - loss: 0.1169 - acc: 0.9646\n",
            "Epoch 00024: val_acc did not improve from 0.82760\n",
            "50000/50000 [==============================] - 13s 269us/sample - loss: 0.1169 - acc: 0.9646 - val_loss: 0.7196 - val_acc: 0.8236\n",
            "Epoch 25/50\n",
            "49920/50000 [============================>.] - ETA: 0s - loss: 0.1231 - acc: 0.9624\n",
            "Epoch 00025: val_acc improved from 0.82760 to 0.82900, saving model to /content/model_weight_cifar10_best.h5\n",
            "50000/50000 [==============================] - 14s 271us/sample - loss: 0.1231 - acc: 0.9623 - val_loss: 0.6698 - val_acc: 0.8290\n",
            "Epoch 26/50\n",
            "49920/50000 [============================>.] - ETA: 0s - loss: 0.1054 - acc: 0.9684\n",
            "Epoch 00026: val_acc did not improve from 0.82900\n",
            "50000/50000 [==============================] - 13s 269us/sample - loss: 0.1052 - acc: 0.9685 - val_loss: 0.7120 - val_acc: 0.8244\n",
            "Epoch 27/50\n",
            "49920/50000 [============================>.] - ETA: 0s - loss: 0.1123 - acc: 0.9669\n",
            "Epoch 00027: val_acc did not improve from 0.82900\n",
            "50000/50000 [==============================] - 13s 268us/sample - loss: 0.1122 - acc: 0.9669 - val_loss: 0.7395 - val_acc: 0.8220\n",
            "Epoch 28/50\n",
            "49920/50000 [============================>.] - ETA: 0s - loss: 0.1129 - acc: 0.9652\n",
            "Epoch 00028: val_acc did not improve from 0.82900\n",
            "50000/50000 [==============================] - 13s 269us/sample - loss: 0.1129 - acc: 0.9652 - val_loss: 0.7238 - val_acc: 0.8276\n",
            "Epoch 29/50\n",
            "49920/50000 [============================>.] - ETA: 0s - loss: 0.1049 - acc: 0.9683\n",
            "Epoch 00029: val_acc improved from 0.82900 to 0.82960, saving model to /content/model_weight_cifar10_best.h5\n",
            "50000/50000 [==============================] - 14s 272us/sample - loss: 0.1049 - acc: 0.9684 - val_loss: 0.7217 - val_acc: 0.8296\n",
            "Epoch 30/50\n",
            "49920/50000 [============================>.] - ETA: 0s - loss: 0.1005 - acc: 0.9699\n",
            "Epoch 00030: val_acc did not improve from 0.82960\n",
            "50000/50000 [==============================] - 13s 269us/sample - loss: 0.1006 - acc: 0.9699 - val_loss: 0.7298 - val_acc: 0.8252\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3784eee9b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDwuucNTOSd1",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR9WUYXxqtfR",
        "colab_type": "text"
      },
      "source": [
        "# **4. 모델 저장**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wi9yznz4qvzK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_path = '/content/'\n",
        "team_name = 'team10'\n",
        "\n",
        "# 모델의 weight 값만 저장합니다.\n",
        "model.save_weights(save_path + 'model_weight_' + data_type + '_' + team_name + '.h5')\n",
        "\n",
        "# 모델의 구조만을 저장합니다.\n",
        "model_json = model.to_json()\n",
        "with open(save_path + 'model_structure_' + data_type + '_' + team_name + '.json', 'w') as json_file : \n",
        "    json_file.write(model_json)\n",
        "\n",
        "# 트레이닝된 전체 모델을 저장합니다.\n",
        "model.save(save_path +  'model_entire_' + data_type + '_' + team_name + '.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B2BoRDZ7cFl",
        "colab_type": "text"
      },
      "source": [
        "# **5. 모델 로드 및 평가**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDBwxVUx7knQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "3e43249f-658b-4eff-c49d-29fc0566addd"
      },
      "source": [
        "save_path = '/content/'\n",
        "team_name = 'team10'\n",
        "\n",
        "# model = keras.models.load_model(save_path + 'model_entire_' + data_type + '_' + team_name + '.h5')\n",
        "model = keras.models.load_model(save_path + 'model_weight_best.h5')\n",
        "model.evaluate(x_test_after, y_test)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 2s 186us/sample - loss: 0.7991 - acc: 0.8400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7991033857345581, 0.84]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSgqEQ13mgG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}